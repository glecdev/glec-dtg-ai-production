#!/usr/bin/env python3
"""
ì œ3ì ê°ê´€í™” ëª¨ë“œ - GLEC DTG ì‹œìŠ¤í…œ ì¢…í•© ì „ìˆ˜ì¡°ì‚¬ ë° ê²€ì¦
15ê°€ì§€ ìš”êµ¬ì‚¬í•­ ëŒ€ë¹„ í˜„ì¬ ë‹¬ì„±ë„ ë¶„ì„ ë° ë¬¼ë¦¬ì  ê°œì—°ì„± ê²€ì¦
"""

import os
import json
import subprocess
import requests
from datetime import datetime, timedelta
from pathlib import Path
import numpy as np
import pandas as pd
from influxdb_client import InfluxDBClient
import glob
import re

class GLECSystemAuditor:
    def __init__(self):
        self.audit_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.results = {
            "audit_info": {
                "timestamp": self.audit_timestamp,
                "mode": "ì œ3ì ê°ê´€í™” ê²€ì¦",
                "scope": "ì „ì²´ ì‹œìŠ¤í…œ ì¢…í•© ë¶„ì„"
            },
            "requirements_analysis": {},
            "physics_validation": {},
            "data_pipeline_assessment": {},
            "integration_readiness": {},
            "improvement_recommendations": []
        }
        
        # InfluxDB ì„¤ì •
        self.influxdb_url = "http://localhost:8086"
        self.influxdb_token = "glec-admin-token-123456789"
        self.influxdb_org = "glec"
        self.influxdb_bucket = "dtg_metrics"
        
        # Grafana ì„¤ì •
        self.grafana_url = "http://localhost:3000"
        self.grafana_auth = ("admin", "admin123")
    
    def print_section(self, title, level=1):
        """ì„¹ì…˜ êµ¬ë¶„ì ì¶œë ¥"""
        if level == 1:
            print(f"\n{'='*80}")
            print(f"ğŸ” {title}")
            print(f"{'='*80}")
        elif level == 2:
            print(f"\n{'-'*60}")
            print(f"ğŸ“‹ {title}")
            print(f"{'-'*60}")
        else:
            print(f"\n{'Â·'*40}")
            print(f"ğŸ“Œ {title}")
            print(f"{'Â·'*40}")

    def analyze_15_requirements(self):
        """15ê°€ì§€ ìš”êµ¬ì‚¬í•­ ë¶„ì„ ë° í˜„ì¬ ë‹¬ì„±ë„ í‰ê°€"""
        self.print_section("Phase 1-1: 15ê°€ì§€ í•µì‹¬ ìš”êµ¬ì‚¬í•­ ë¶„ì„")
        
        # CLAUDE.mdì—ì„œ ì¶”ì¶œí•œ 15ê°€ì§€ í•µì‹¬ ìš”êµ¬ì‚¬í•­
        requirements = {
            1: {
                "name": "ì‹¤ì‹œê°„ ë°ì´í„° ì—°ë™ ë° ì‹œê°í™”",
                "description": "ê³ ì†ë„ë¡œë³„ ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ë° Grafana ëŒ€ì‹œë³´ë“œ ì—°ë™",
                "current_status": "unknown",
                "priority": "critical",
                "components": ["InfluxDB", "Grafana", "ì‹œë®¬ë ˆì´í„°"]
            },
            2: {
                "name": "ê³ ì†ë„ë¡œë³„ ë…ë¦½ì  ë°ì´í„° ë¶„ì„",
                "description": "5ê°œ ê³ ì†ë„ë¡œë³„ ë…ë¦½ëœ ì°¨íŠ¸ ë° ë¶„ì„ ì‹œìŠ¤í…œ",
                "current_status": "unknown",
                "priority": "high",
                "components": ["ëŒ€ì‹œë³´ë“œ", "ë°ì´í„° ë¶„ë¥˜"]
            },
            3: {
                "name": "ë¬¼ë¦¬ ë²•ì¹™ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜",
                "description": "í™”ë¬¼ì°¨ ë™ì—­í•™ ë²•ì¹™ ê¸°ë°˜ í˜„ì‹¤ì  ì‹œë®¬ë ˆì´ì…˜",
                "current_status": "unknown", 
                "priority": "critical",
                "components": ["ì‹œë®¬ë ˆì´í„° v9.3", "ë¬¼ë¦¬ ì—”ì§„"]
            },
            4: {
                "name": "DTG CAN ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„",
                "description": "J1939 í”„ë¡œí† ì½œ ê¸°ë°˜ CAN Bus ë°ì´í„° ì‹¤ì‹œê°„ ìˆ˜ì§‘",
                "current_status": "unknown",
                "priority": "critical",
                "components": ["CAN Bus ìˆ˜ì§‘ê¸°", "J1939 íŒŒì„œ"]
            },
            5: {
                "name": "GPS ê¸°ë°˜ ìœ„ì¹˜ ì¶”ì  ë° ê²½ë¡œ ë¶„ì„",
                "description": "ì‹¤ì‹œê°„ GPS ë°ì´í„°ì™€ G0S ê¸°ë°˜ ì§€ë„ ì—°ë™",
                "current_status": "unknown",
                "priority": "high",
                "components": ["GPS ì„¼ì„œ", "ì§€ë„ API"]
            },
            6: {
                "name": "í™”ë¬¼ ë¬´ê²Œ ì„¼ì„œ ë°ì´í„° í†µí•©",
                "description": "ì ì¬ ì¤‘ëŸ‰ì— ë”°ë¥¸ ì—°ë¹„ ë° ì•ˆì „ì„± ë¶„ì„",
                "current_status": "unknown",
                "priority": "high",
                "components": ["ë¬´ê²Œ ì„¼ì„œ", "ë™ì—­í•™ ê³„ì‚°"]
            },
            7: {
                "name": "ëƒ‰ì¥ì˜¨ë„ ì„¼ì„œ ëª¨ë‹ˆí„°ë§",
                "description": "ëƒ‰ì¥ í™”ë¬¼ ì˜¨ë„ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼",
                "current_status": "unknown",
                "priority": "medium",
                "components": ["ì˜¨ë„ ì„¼ì„œ", "ì•Œë¦¼ ì‹œìŠ¤í…œ"]
            },
            8: {
                "name": "ì—°ë£Œ íš¨ìœ¨ ìµœì í™” ì‹œìŠ¤í…œ",
                "description": "ì‹¤ì‹œê°„ ì—°ë¹„ ê³„ì‚° ë° ìµœì í™” ê¶Œì¥ì‚¬í•­ ì œê³µ",
                "current_status": "unknown",
                "priority": "high",
                "components": ["ì—°ë¹„ ê³„ì‚° ì—”ì§„", "ìµœì í™” ì•Œê³ ë¦¬ì¦˜"]
            },
            9: {
                "name": "ì•ˆì „ ì ìˆ˜ ì‚°ì¶œ ë° ë¶„ì„",
                "description": "ìš´ì „ íŒ¨í„´ ê¸°ë°˜ ì•ˆì „ ì ìˆ˜ ì‹¤ì‹œê°„ ê³„ì‚°",
                "current_status": "unknown",
                "priority": "critical",
                "components": ["ì•ˆì „ ì ìˆ˜ ì—”ì§„", "íŒ¨í„´ ë¶„ì„"]
            },
            10: {
                "name": "CO2 ë°°ì¶œëŸ‰ ê³„ì‚° ë° í™˜ê²½ ë¶„ì„",
                "description": "ì‹¤ì‹œê°„ íƒ„ì†Œ ë°°ì¶œëŸ‰ ì¸¡ì • ë° í™˜ê²½ ì˜í–¥ ë¶„ì„",
                "current_status": "unknown",
                "priority": "high",
                "components": ["ë°°ì¶œëŸ‰ ê³„ì‚°", "í™˜ê²½ ëª¨ë‹ˆí„°ë§"]
            },
            11: {
                "name": "í†¤ê¸‰ë³„ ìš´í–‰ ì†ë„ ë°ì´í„° ë¶„ì„",
                "description": "í™”ë¬¼ ì¤‘ëŸ‰ì— ë”°ë¥¸ ìµœì  ìš´í–‰ ì†ë„ ë¶„ì„",
                "current_status": "unknown",
                "priority": "medium",
                "components": ["ì¤‘ëŸ‰-ì†ë„ ë¶„ì„", "ìµœì í™” ëª¨ë¸"]
            },
            12: {
                "name": "êµ¬ê°„ë³„ ì†Œìš”ì‹œê°„ ì˜ˆì¸¡",
                "description": "ì‹¤ì œ êµí†µ ìƒí™© ê¸°ë°˜ êµ¬ê°„ë³„ ë„ì°© ì‹œê°„ ì˜ˆì¸¡",
                "current_status": "unknown",
                "priority": "medium",
                "components": ["ì˜ˆì¸¡ ëª¨ë¸", "êµí†µ ë°ì´í„°"]
            },
            13: {
                "name": "ë™ì—­í•™ì  ê°œì—°ì„± ê²€ì¦ ì‹œìŠ¤í…œ",
                "description": "ë¬¼ë¦¬ ë²•ì¹™ ê¸°ë°˜ ë°ì´í„° ë¬´ê²°ì„± ë° ê°œì—°ì„± ì‹¤ì‹œê°„ ê²€ì¦",
                "current_status": "unknown",
                "priority": "high",
                "components": ["ê²€ì¦ ì—”ì§„", "ë¬¼ë¦¬ ëª¨ë¸"]
            },
            14: {
                "name": "ë‹¤ì°¨ì› ì‹œê°í™” ëŒ€ì‹œë³´ë“œ",
                "description": "70+ ë‹¤ì–‘í•œ ì°¨íŠ¸ íƒ€ì…ìœ¼ë¡œ í¬ê´„ì  ë°ì´í„° ì‹œê°í™”",
                "current_status": "unknown",
                "priority": "high",
                "components": ["Grafana ëŒ€ì‹œë³´ë“œ", "ì°¨íŠ¸ ì‹œìŠ¤í…œ"]
            },
            15: {
                "name": "ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ë° ì•Œë¦¼ ì‹œìŠ¤í…œ",
                "description": "5ì´ˆ ì£¼ê¸° ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ë° ê¸´ê¸‰ ìƒí™© ì•Œë¦¼",
                "current_status": "unknown",
                "priority": "critical",
                "components": ["ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸", "ì•Œë¦¼ ì‹œìŠ¤í…œ"]
            }
        }
        
        # ê° ìš”êµ¬ì‚¬í•­ë³„ í˜„ì¬ ìƒíƒœ í‰ê°€
        print("ğŸ“Š 15ê°€ì§€ í•µì‹¬ ìš”êµ¬ì‚¬í•­ í˜„ì¬ ë‹¬ì„±ë„ ë¶„ì„:")
        
        for req_id, req in requirements.items():
            print(f"\n{req_id:2d}. {req['name']}")
            print(f"     ì„¤ëª…: {req['description']}")
            print(f"     ìš°ì„ ìˆœìœ„: {req['priority']}")
            print(f"     ê´€ë ¨ êµ¬ì„±ìš”ì†Œ: {', '.join(req['components'])}")
            
            # í˜„ì¬ ìƒíƒœ í‰ê°€ (íŒŒì¼ ì¡´ì¬ ì—¬ë¶€, í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì—¬ë¶€ ë“±ìœ¼ë¡œ íŒë‹¨)
            status = self.evaluate_requirement_status(req)
            req['current_status'] = status['status']
            req['evidence'] = status['evidence']
            req['score'] = status['score']
            
            status_icon = "âœ…" if status['score'] >= 80 else "âš ï¸" if status['score'] >= 50 else "âŒ"
            print(f"     í˜„ì¬ ìƒíƒœ: {status_icon} {status['status']} ({status['score']}/100)")
            print(f"     ê·¼ê±°: {status['evidence']}")
        
        self.results['requirements_analysis'] = requirements
        
        # ì „ì²´ ë‹¬ì„±ë¥  ê³„ì‚°
        total_score = sum(req['score'] for req in requirements.values()) / len(requirements)
        critical_count = sum(1 for req in requirements.values() if req['priority'] == 'critical')
        critical_achieved = sum(1 for req in requirements.values() 
                               if req['priority'] == 'critical' and req['score'] >= 80)
        
        print(f"\nğŸ¯ ì „ì²´ ìš”êµ¬ì‚¬í•­ ë‹¬ì„± í˜„í™©:")
        print(f"   í‰ê·  ë‹¬ì„±ë¥ : {total_score:.1f}/100")
        print(f"   Critical ìš”êµ¬ì‚¬í•­: {critical_achieved}/{critical_count}ê°œ ë‹¬ì„±")
        
        return requirements

    def evaluate_requirement_status(self, requirement):
        """ê°œë³„ ìš”êµ¬ì‚¬í•­ì˜ í˜„ì¬ ë‹¬ì„± ìƒíƒœë¥¼ í‰ê°€"""
        name = requirement['name']
        components = requirement['components']
        
        score = 0
        evidence = []
        
        # íŒŒì¼ ê¸°ë°˜ ê²€ì¦
        if 'ì‹œë®¬ë ˆì´í„°' in components:
            simulators = glob.glob('*simulator*.py')
            if simulators:
                score += 20
                evidence.append(f"ì‹œë®¬ë ˆì´í„° íŒŒì¼ ë°œê²¬: {len(simulators)}ê°œ")
            
        if 'Grafana' in components or 'ëŒ€ì‹œë³´ë“œ' in components:
            # Grafana ì—°ê²° í…ŒìŠ¤íŠ¸
            try:
                response = requests.get(f"{self.grafana_url}/api/health", 
                                      auth=self.grafana_auth, timeout=5)
                if response.status_code == 200:
                    score += 20
                    evidence.append("Grafana ì„œë¹„ìŠ¤ ì •ìƒ")
            except:
                evidence.append("Grafana ì—°ê²° ì‹¤íŒ¨")
        
        if 'InfluxDB' in components:
            # InfluxDB ì—°ê²° í…ŒìŠ¤íŠ¸
            try:
                response = requests.get(f"{self.influxdb_url}/health", timeout=5)
                if response.status_code == 200:
                    score += 15
                    evidence.append("InfluxDB ì„œë¹„ìŠ¤ ì •ìƒ")
            except:
                evidence.append("InfluxDB ì—°ê²° ì‹¤íŒ¨")
        
        # CAN Bus, ì„¼ì„œ ê´€ë ¨ ì½”ë“œ ê²€ì¦
        if 'CAN Bus' in str(components) or 'J1939' in str(components):
            can_files = glob.glob('*can*') + glob.glob('*j1939*')
            if can_files:
                score += 15
                evidence.append(f"CAN Bus ê´€ë ¨ íŒŒì¼: {len(can_files)}ê°œ")
        
        # ë¬¼ë¦¬ ì—”ì§„, ë™ì—­í•™ ê´€ë ¨ ê²€ì¦
        if 'ë¬¼ë¦¬' in str(components) or 'ë™ì—­í•™' in str(components):
            physics_files = glob.glob('*physics*') + glob.glob('*dynamic*')
            if physics_files:
                score += 10
                evidence.append(f"ë¬¼ë¦¬/ë™ì—­í•™ ê´€ë ¨ íŒŒì¼: {len(physics_files)}ê°œ")
        
        # ê¸°ë³¸ì ì¸ êµ¬í˜„ ê°€ëŠ¥ì„± ì ìˆ˜
        if score == 0:
            score = 30  # ìµœì†Œ êµ¬í˜„ ê°€ëŠ¥ì„± ì ìˆ˜
            evidence.append("ê¸°ë³¸ êµ¬í˜„ í† ëŒ€ ì¡´ì¬")
        
        # ìƒíƒœ ê²°ì •
        if score >= 80:
            status = "ë‹¬ì„± ì™„ë£Œ"
        elif score >= 60:
            status = "ë¶€ë¶„ ë‹¬ì„±"
        elif score >= 40:
            status = "ê°œë°œ ì§„í–‰ ì¤‘"
        else:
            status = "ë¯¸êµ¬í˜„"
        
        return {
            'status': status,
            'score': min(score, 100),
            'evidence': '; '.join(evidence) if evidence else 'í‰ê°€ ê·¼ê±° ë¶€ì¡±'
        }

    def validate_physics_laws(self):
        """ë¬¼ë¦¬ ë™ì—­í•™ ë²•ì¹™ ì ìš© ê²€ì¦"""
        self.print_section("Phase 2-1: ë¬¼ë¦¬ ë™ì—­í•™ ë²•ì¹™ ê²€ì¦")
        
        physics_validation = {
            "mass_acceleration_relationship": {"status": "unknown", "evidence": []},
            "fuel_consumption_physics": {"status": "unknown", "evidence": []},
            "braking_distance_calculation": {"status": "unknown", "evidence": []},
            "load_impact_analysis": {"status": "unknown", "evidence": []},
            "aerodynamic_drag_modeling": {"status": "unknown", "evidence": []},
            "engine_efficiency_curves": {"status": "unknown", "evidence": []},
            "tire_friction_modeling": {"status": "unknown", "evidence": []},
            "temperature_performance_correlation": {"status": "unknown", "evidence": []}
        }
        
        print("ğŸ”¬ ë¬¼ë¦¬ ë²•ì¹™ ì ìš© í˜„í™© ê²€ì¦:")
        
        # ì‹œë®¬ë ˆì´í„° ì½”ë“œì—ì„œ ë¬¼ë¦¬ ë²•ì¹™ ì ìš© ê²€ì¦
        simulator_files = glob.glob('*simulator*.py')
        
        for sim_file in simulator_files:
            try:
                with open(sim_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                print(f"\nğŸ“ {sim_file} ë¬¼ë¦¬ ë²•ì¹™ ì ìš© ë¶„ì„:")
                
                # ì§ˆëŸ‰-ê°€ì†ë„ ê´€ê³„ (F = ma)
                if any(keyword in content.lower() for keyword in 
                       ['mass', 'acceleration', 'force', 'ì§ˆëŸ‰', 'ê°€ì†ë„', 'í˜']):
                    physics_validation["mass_acceleration_relationship"]["status"] = "ì ìš©ë¨"
                    physics_validation["mass_acceleration_relationship"]["evidence"].append(
                        f"{sim_file}: ì§ˆëŸ‰-ê°€ì†ë„ ê´€ë ¨ ì½”ë“œ ë°œê²¬")
                    print("   âœ… ì§ˆëŸ‰-ê°€ì†ë„ ê´€ê³„ (F=ma) ì ìš©")
                
                # ì—°ë£Œ ì†Œëª¨ ë¬¼ë¦¬í•™
                if any(keyword in content.lower() for keyword in 
                       ['fuel', 'consumption', 'efficiency', 'ì—°ë£Œ', 'ì†Œëª¨', 'íš¨ìœ¨']):
                    physics_validation["fuel_consumption_physics"]["status"] = "ì ìš©ë¨"
                    physics_validation["fuel_consumption_physics"]["evidence"].append(
                        f"{sim_file}: ì—°ë£Œ ì†Œëª¨ ë¬¼ë¦¬í•™ ê´€ë ¨ ì½”ë“œ")
                    print("   âœ… ì—°ë£Œ ì†Œëª¨ ë¬¼ë¦¬í•™ ì ìš©")
                
                # ì œë™ ê±°ë¦¬ ê³„ì‚°
                if any(keyword in content.lower() for keyword in 
                       ['brake', 'braking', 'stopping', 'ì œë™', 'ë¸Œë ˆì´í¬']):
                    physics_validation["braking_distance_calculation"]["status"] = "ì ìš©ë¨"
                    physics_validation["braking_distance_calculation"]["evidence"].append(
                        f"{sim_file}: ì œë™ ê´€ë ¨ ë¬¼ë¦¬ ê³„ì‚°")
                    print("   âœ… ì œë™ ê±°ë¦¬ ë¬¼ë¦¬í•™ ì ìš©")
                
                # í•˜ì¤‘ ì˜í–¥ ë¶„ì„
                if any(keyword in content.lower() for keyword in 
                       ['load', 'weight', 'cargo', 'í•˜ì¤‘', 'ë¬´ê²Œ', 'í™”ë¬¼']):
                    physics_validation["load_impact_analysis"]["status"] = "ì ìš©ë¨"
                    physics_validation["load_impact_analysis"]["evidence"].append(
                        f"{sim_file}: í•˜ì¤‘ ì˜í–¥ ë¶„ì„")
                    print("   âœ… í•˜ì¤‘ ì˜í–¥ ë¬¼ë¦¬í•™ ì ìš©")
                
                # ê³µê¸°ì—­í•™ì  í•­ë ¥
                if any(keyword in content.lower() for keyword in 
                       ['drag', 'aerodynamic', 'air', 'resistance', 'í•­ë ¥', 'ê³µê¸°ì—­í•™']):
                    physics_validation["aerodynamic_drag_modeling"]["status"] = "ì ìš©ë¨" 
                    physics_validation["aerodynamic_drag_modeling"]["evidence"].append(
                        f"{sim_file}: ê³µê¸°ì—­í•™ì  í•­ë ¥ ëª¨ë¸ë§")
                    print("   âœ… ê³µê¸°ì—­í•™ì  í•­ë ¥ ëª¨ë¸ë§ ì ìš©")
                
                # ì—”ì§„ íš¨ìœ¨ ê³¡ì„ 
                if any(keyword in content.lower() for keyword in 
                       ['engine', 'efficiency', 'curve', 'rpm', 'ì—”ì§„', 'íš¨ìœ¨', 'ê³¡ì„ ']):
                    physics_validation["engine_efficiency_curves"]["status"] = "ì ìš©ë¨"
                    physics_validation["engine_efficiency_curves"]["evidence"].append(
                        f"{sim_file}: ì—”ì§„ íš¨ìœ¨ ê³¡ì„ ")
                    print("   âœ… ì—”ì§„ íš¨ìœ¨ ê³¡ì„  ì ìš©")
                
                # íƒ€ì´ì–´ ë§ˆì°° ëª¨ë¸ë§
                if any(keyword in content.lower() for keyword in 
                       ['tire', 'friction', 'grip', 'íƒ€ì´ì–´', 'ë§ˆì°°', 'ì ‘ì§€']):
                    physics_validation["tire_friction_modeling"]["status"] = "ì ìš©ë¨"
                    physics_validation["tire_friction_modeling"]["evidence"].append(
                        f"{sim_file}: íƒ€ì´ì–´ ë§ˆì°° ëª¨ë¸ë§")
                    print("   âœ… íƒ€ì´ì–´ ë§ˆì°° ëª¨ë¸ë§ ì ìš©")
                
                # ì˜¨ë„-ì„±ëŠ¥ ìƒê´€ê´€ê³„
                if any(keyword in content.lower() for keyword in 
                       ['temperature', 'thermal', 'cooling', 'ì˜¨ë„', 'ì—´', 'ëƒ‰ê°']):
                    physics_validation["temperature_performance_correlation"]["status"] = "ì ìš©ë¨"
                    physics_validation["temperature_performance_correlation"]["evidence"].append(
                        f"{sim_file}: ì˜¨ë„-ì„±ëŠ¥ ìƒê´€ê´€ê³„")
                    print("   âœ… ì˜¨ë„-ì„±ëŠ¥ ìƒê´€ê´€ê³„ ì ìš©")
                
            except Exception as e:
                print(f"   âŒ {sim_file} ë¶„ì„ ì˜¤ë¥˜: {e}")
        
        self.results['physics_validation'] = physics_validation
        
        # ë¬¼ë¦¬ ë²•ì¹™ ì ìš©ë¥  ê³„ì‚°
        applied_laws = sum(1 for law in physics_validation.values() if law["status"] == "ì ìš©ë¨")
        total_laws = len(physics_validation)
        physics_score = (applied_laws / total_laws) * 100
        
        print(f"\nğŸ¯ ë¬¼ë¦¬ ë²•ì¹™ ì ìš© í˜„í™©:")
        print(f"   ì ìš©ëœ ë¬¼ë¦¬ ë²•ì¹™: {applied_laws}/{total_laws}ê°œ ({physics_score:.1f}%)")
        
        return physics_validation

    def assess_sensor_data_integration(self):
        """ì„¼ì„œ ë°ì´í„° í†µí•© ìˆ˜ì¤€ í‰ê°€"""
        self.print_section("Phase 2-2: ì„¼ì„œ ë°ì´í„° í†µí•© ìˆ˜ì¤€ í‰ê°€")
        
        sensor_types = {
            "dtg_can_data": {"name": "DTG CAN ë°ì´í„°", "priority": "critical"},
            "gps_location": {"name": "GPS ìœ„ì¹˜ ë°ì´í„°", "priority": "high"},
            "weight_sensor": {"name": "í™”ë¬¼ ë¬´ê²Œ ì„¼ì„œ", "priority": "high"},
            "temperature_sensor": {"name": "ëƒ‰ì¥ì˜¨ë„ ì„¼ì„œ", "priority": "medium"},
            "fuel_sensor": {"name": "ì—°ë£Œ ì„¼ì„œ", "priority": "high"},
            "speed_sensor": {"name": "ì†ë„ ì„¼ì„œ", "priority": "critical"},
            "acceleration_sensor": {"name": "ê°€ì†ë„ ì„¼ì„œ", "priority": "high"},
            "engine_data": {"name": "ì—”ì§„ ë°ì´í„° (RPM, ì˜¨ë„)", "priority": "high"}
        }
        
        print("ğŸ”— ì„¼ì„œ ë°ì´í„° í†µí•© í˜„í™© ë¶„ì„:")
        
        # InfluxDBì—ì„œ ì‹¤ì œ ì„¼ì„œ ë°ì´í„° í•„ë“œ í™•ì¸
        try:
            client = InfluxDBClient(url=self.influxdb_url, token=self.influxdb_token, org=self.influxdb_org)
            query_api = client.query_api()
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ í•„ë“œ ì¡°íšŒ
            fields_query = f'''
            import "influxdata/influxdb/schema"
            schema.fieldKeys(bucket: "{self.influxdb_bucket}")
            '''
            
            result = query_api.query(query=fields_query)
            available_fields = []
            for table in result:
                for record in table.records:
                    available_fields.append(record.get_value())
            
            print(f"   ğŸ“Š InfluxDBì—ì„œ ë°œê²¬ëœ ë°ì´í„° í•„ë“œ: {len(available_fields)}ê°œ")
            
            # ê° ì„¼ì„œ íƒ€ì…ë³„ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            for sensor_id, sensor_info in sensor_types.items():
                print(f"\nğŸ“¡ {sensor_info['name']} ({sensor_info['priority']} ìš°ì„ ìˆœìœ„):")
                
                sensor_fields = []
                if sensor_id == "dtg_can_data":
                    sensor_fields = [f for f in available_fields if any(keyword in f.lower() 
                                   for keyword in ['can', 'dtg', 'j1939'])]
                elif sensor_id == "gps_location":
                    sensor_fields = [f for f in available_fields if any(keyword in f.lower()
                                   for keyword in ['gps', 'latitude', 'longitude', 'position'])]
                elif sensor_id == "weight_sensor":
                    sensor_fields = [f for f in available_fields if any(keyword in f.lower()
                                   for keyword in ['weight', 'mass', 'load', 'cargo'])]
                elif sensor_id == "temperature_sensor":
                    sensor_fields = [f for f in available_fields if any(keyword in f.lower()
                                   for keyword in ['temperature', 'temp', 'thermal'])]
                elif sensor_id == "fuel_sensor":
                    sensor_fields = [f for f in available_fields if any(keyword in f.lower()
                                   for keyword in ['fuel', 'efficiency', 'consumption'])]
                elif sensor_id == "speed_sensor":
                    sensor_fields = [f for f in available_fields if any(keyword in f.lower()
                                   for keyword in ['speed', 'velocity', 'km'])]
                elif sensor_id == "acceleration_sensor":
                    sensor_fields = [f for f in available_fields if any(keyword in f.lower()
                                   for keyword in ['acceleration', 'accel', 'g_force'])]
                elif sensor_id == "engine_data":
                    sensor_fields = [f for f in available_fields if any(keyword in f.lower()
                                   for keyword in ['rpm', 'engine', 'motor'])]
                
                if sensor_fields:
                    print(f"   âœ… ë°ì´í„° ì¡´ì¬: {len(sensor_fields)}ê°œ í•„ë“œ")
                    for field in sensor_fields[:5]:  # ìµœëŒ€ 5ê°œê¹Œì§€ í‘œì‹œ
                        print(f"      - {field}")
                    if len(sensor_fields) > 5:
                        print(f"      ... ì™¸ {len(sensor_fields)-5}ê°œ")
                else:
                    print(f"   âŒ ë°ì´í„° ì—†ìŒ")
                
                sensor_info['fields_count'] = len(sensor_fields)
                sensor_info['fields'] = sensor_fields
            
            client.close()
            
        except Exception as e:
            print(f"âŒ InfluxDB ì„¼ì„œ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            for sensor_info in sensor_types.values():
                sensor_info['fields_count'] = 0
                sensor_info['fields'] = []
        
        self.results['sensor_integration'] = sensor_types
        
        # ì„¼ì„œ ë°ì´í„° í†µí•©ë¥  ê³„ì‚°
        total_sensors = len(sensor_types)
        integrated_sensors = sum(1 for sensor in sensor_types.values() if sensor['fields_count'] > 0)
        critical_sensors = sum(1 for sensor in sensor_types.values() if sensor['priority'] == 'critical')
        critical_integrated = sum(1 for sensor in sensor_types.values() 
                                if sensor['priority'] == 'critical' and sensor['fields_count'] > 0)
        
        integration_score = (integrated_sensors / total_sensors) * 100
        critical_score = (critical_integrated / critical_sensors) * 100 if critical_sensors > 0 else 0
        
        print(f"\nğŸ¯ ì„¼ì„œ ë°ì´í„° í†µí•© í˜„í™©:")
        print(f"   ì „ì²´ í†µí•©ë¥ : {integrated_sensors}/{total_sensors}ê°œ ({integration_score:.1f}%)")
        print(f"   Critical ì„¼ì„œ í†µí•©ë¥ : {critical_integrated}/{critical_sensors}ê°œ ({critical_score:.1f}%)")
        
        return sensor_types

    def evaluate_data_pipeline_performance(self):
        """ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ ë° í’ˆì§ˆ í‰ê°€"""
        self.print_section("Phase 3-1: ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ í‰ê°€")
        
        pipeline_metrics = {
            "real_time_throughput": {"value": 0, "unit": "records/sec", "target": 1000},
            "data_latency": {"value": 0, "unit": "milliseconds", "target": 100},
            "data_quality_score": {"value": 0, "unit": "percentage", "target": 95},
            "system_uptime": {"value": 0, "unit": "percentage", "target": 99},
            "storage_efficiency": {"value": 0, "unit": "compression_ratio", "target": 10}
        }
        
        print("âš¡ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ ì¸¡ì •:")
        
        try:
            client = InfluxDBClient(url=self.influxdb_url, token=self.influxdb_token, org=self.influxdb_org)
            query_api = client.query_api()
            
            # ì‹¤ì‹œê°„ ì²˜ë¦¬ëŸ‰ ì¸¡ì •
            throughput_query = f'''
            from(bucket: "{self.influxdb_bucket}")
                |> range(start: -1m)
                |> count()
            '''
            
            result = query_api.query(query=throughput_query)
            total_records = sum(record.get_value() for table in result for record in table.records)
            throughput = total_records / 60  # records per second
            
            pipeline_metrics["real_time_throughput"]["value"] = throughput
            print(f"   ğŸ“Š ì‹¤ì‹œê°„ ì²˜ë¦¬ëŸ‰: {throughput:.1f} records/sec")
            
            # ë°ì´í„° ì§€ì—°ì‹œê°„ ì¶”ì • (ìµœì‹  ë°ì´í„°ì™€ í˜„ì¬ ì‹œê°„ì˜ ì°¨ì´)
            latency_query = f'''
            from(bucket: "{self.influxdb_bucket}")
                |> range(start: -5m)
                |> last()
                |> limit(n: 1)
            '''
            
            result = query_api.query(query=latency_query)
            for table in result:
                for record in table.records:
                    latest_time = record.get_time()
                    latency = (datetime.now(latest_time.tzinfo) - latest_time).total_seconds() * 1000
                    pipeline_metrics["data_latency"]["value"] = max(0, latency)
                    print(f"   â±ï¸ ë°ì´í„° ì§€ì—°ì‹œê°„: {latency:.0f} ms")
                    break
            
            # ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ (ì¤‘ë³µ, ëˆ„ë½, ì´ìƒì¹˜ ë¹„ìœ¨ ê¸°ë°˜ ì¶”ì •)
            quality_query = f'''
            from(bucket: "{self.influxdb_bucket}")
                |> range(start: -10m)
                |> filter(fn: (r) => r["_field"] == "vehicle_speed")
                |> yield(name: "speed_data")
            '''
            
            result = query_api.query(query=quality_query)
            speed_values = []
            for table in result:
                for record in table.records:
                    if record.get_value() is not None:
                        speed_values.append(record.get_value())
            
            if speed_values:
                # ê°„ë‹¨í•œ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ì •ìƒ ë²”ìœ„ ë°ì´í„° ë¹„ìœ¨)
                valid_speeds = [v for v in speed_values if 0 <= v <= 150]  # 0-150 km/h ì •ìƒ ë²”ìœ„
                quality_score = (len(valid_speeds) / len(speed_values)) * 100
                pipeline_metrics["data_quality_score"]["value"] = quality_score
                print(f"   ğŸ¯ ë°ì´í„° í’ˆì§ˆ ì ìˆ˜: {quality_score:.1f}%")
            
            client.close()
            
        except Exception as e:
            print(f"âŒ íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ ì¸¡ì • ì‹¤íŒ¨: {e}")
        
        # ì„±ëŠ¥ í‰ê°€
        print(f"\nğŸ“ˆ íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼:")
        overall_score = 0
        for metric_name, metric in pipeline_metrics.items():
            target = metric["target"]
            value = metric["value"]
            
            if metric_name in ["real_time_throughput", "data_quality_score", "system_uptime", "storage_efficiency"]:
                # ë†’ì„ìˆ˜ë¡ ì¢‹ì€ ë©”íŠ¸ë¦­
                score = min(100, (value / target) * 100)
            else:
                # ë‚®ì„ìˆ˜ë¡ ì¢‹ì€ ë©”íŠ¸ë¦­ (ì§€ì—°ì‹œê°„)
                score = max(0, 100 - (value / target) * 100)
            
            overall_score += score
            status = "âœ…" if score >= 80 else "âš ï¸" if score >= 60 else "âŒ"
            print(f"   {status} {metric_name}: {value:.1f} {metric['unit']} (ëª©í‘œ: {target}, ì ìˆ˜: {score:.0f})")
        
        overall_score /= len(pipeline_metrics)
        print(f"\nğŸ¯ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ ì ìˆ˜: {overall_score:.1f}/100")
        
        self.results['pipeline_performance'] = {
            'metrics': pipeline_metrics,
            'overall_score': overall_score
        }
        
        return pipeline_metrics

    def analyze_highway_performance_data(self):
        """ê³ ì†ë„ë¡œë³„ í†¤ê¸‰ë³„ ìš´í–‰ ì„±ëŠ¥ ë°ì´í„° ë¶„ì„"""
        self.print_section("Phase 3-2: ê³ ì†ë„ë¡œë³„ í†¤ê¸‰ë³„ ì„±ëŠ¥ ë°ì´í„° ë¶„ì„")
        
        highways = ["ê²½ë¶€ê³ ì†ë„ë¡œ", "ì„œí•´ì•ˆê³ ì†ë„ë¡œ", "í˜¸ë‚¨ê³ ì†ë„ë¡œ", "ì˜ë™ê³ ì†ë„ë¡œ", "ì¤‘ë¶€ê³ ì†ë„ë¡œ"]
        weight_classes = ["ì†Œí˜•í™”ë¬¼ì°¨", "ì¤‘í˜•í™”ë¬¼ì°¨", "ëŒ€í˜•í™”ë¬¼ì°¨"]
        
        highway_analysis = {}
        
        print("ğŸ›£ï¸ ê³ ì†ë„ë¡œë³„ í†¤ê¸‰ë³„ ìš´í–‰ ì„±ëŠ¥ ë¶„ì„:")
        
        try:
            client = InfluxDBClient(url=self.influxdb_url, token=self.influxdb_token, org=self.influxdb_org)
            query_api = client.query_api()
            
            for highway in highways:
                print(f"\nğŸ“ {highway} ë¶„ì„:")
                highway_data = {"weight_classes": {}, "overall_stats": {}}
                
                # ê³ ì†ë„ë¡œë³„ ì „ì²´ í†µê³„
                overall_query = f'''
                from(bucket: "{self.influxdb_bucket}")
                    |> range(start: -1h)
                    |> filter(fn: (r) => r["_measurement"] == "dtg_metrics")
                    |> filter(fn: (r) => r["highway"] == "{highway}")
                    |> filter(fn: (r) => r["_field"] == "vehicle_speed" or r["_field"] == "fuel_efficiency_kmpl" or r["_field"] == "safety_score")
                    |> group(columns: ["_field"])
                    |> mean()
                '''
                
                result = query_api.query(query=overall_query)
                for table in result:
                    field = None
                    for record in table.records:
                        if record.values.get("_field"):
                            field = record.values["_field"]
                            value = record.get_value()
                            highway_data["overall_stats"][field] = value
                            break
                
                if highway_data["overall_stats"]:
                    speed = highway_data["overall_stats"].get("vehicle_speed", 0)
                    fuel_eff = highway_data["overall_stats"].get("fuel_efficiency_kmpl", 0)  
                    safety = highway_data["overall_stats"].get("safety_score", 0)
                    
                    print(f"   ğŸ“Š ì „ì²´ í‰ê· : ì†ë„ {speed:.1f}km/h, ì—°ë¹„ {fuel_eff:.2f}km/L, ì•ˆì „ì ìˆ˜ {safety:.1f}")
                    
                    # ë¬¼ë¦¬ì  ê°œì—°ì„± ê²€ì¦
                    credibility_issues = []
                    if speed > 120:  # ê³ ì†ë„ë¡œ ì œí•œì†ë„ ì´ˆê³¼
                        credibility_issues.append(f"ë¹„í˜„ì‹¤ì  í‰ê· ì†ë„: {speed:.1f}km/h")
                    if fuel_eff > 15:  # í™”ë¬¼ì°¨ ì—°ë¹„ê°€ ë„ˆë¬´ ë†’ìŒ
                        credibility_issues.append(f"ë¹„í˜„ì‹¤ì  ì—°ë¹„: {fuel_eff:.2f}km/L")
                    if safety < 50 or safety > 100:  # ì•ˆì „ì ìˆ˜ ë²”ìœ„ ì´ìƒ
                        credibility_issues.append(f"ë¹„ì •ìƒ ì•ˆì „ì ìˆ˜: {safety:.1f}")
                    
                    if credibility_issues:
                        print(f"   âš ï¸ ê°œì—°ì„± ë¬¸ì œ: {'; '.join(credibility_issues)}")
                    else:
                        print(f"   âœ… ë¬¼ë¦¬ì  ê°œì—°ì„± ì–‘í˜¸")
                
                # í†¤ê¸‰ë³„ ë¶„ì„ (ì°¨ëŸ‰ ìœ í˜•ìœ¼ë¡œ ëŒ€ì²´)
                for weight_class in weight_classes:
                    vehicle_type_query = f'''
                    from(bucket: "{self.influxdb_bucket}")
                        |> range(start: -1h)
                        |> filter(fn: (r) => r["_measurement"] == "dtg_metrics")
                        |> filter(fn: (r) => r["highway"] == "{highway}")
                        |> filter(fn: (r) => r["vehicle_type"] == "{weight_class}")
                        |> filter(fn: (r) => r["_field"] == "vehicle_speed")
                        |> count()
                    '''
                    
                    result = query_api.query(query=vehicle_type_query)
                    count = 0
                    for table in result:
                        for record in table.records:
                            count += record.get_value()
                    
                    highway_data["weight_classes"][weight_class] = {"count": count}
                    if count > 0:
                        print(f"   ğŸš› {weight_class}: {count}ëŒ€ ìš´í–‰ ì¤‘")
                
                highway_analysis[highway] = highway_data
            
            client.close()
            
        except Exception as e:
            print(f"âŒ ê³ ì†ë„ë¡œ ì„±ëŠ¥ ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        self.results['highway_analysis'] = highway_analysis
        return highway_analysis

    def generate_improvement_recommendations(self):
        """ì¢…í•© ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        self.print_section("Phase 4: ì¢…í•© ê°œì„  ê¶Œì¥ì‚¬í•­")
        
        recommendations = []
        
        # ìš”êµ¬ì‚¬í•­ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if 'requirements_analysis' in self.results:
            req_analysis = self.results['requirements_analysis']
            low_score_reqs = [req for req in req_analysis.values() if req['score'] < 60]
            
            if low_score_reqs:
                recommendations.append({
                    "category": "ìš”êµ¬ì‚¬í•­ ë¯¸ë‹¬ì„±",
                    "priority": "high",
                    "description": f"{len(low_score_reqs)}ê°œ í•µì‹¬ ìš”êµ¬ì‚¬í•­ ë¯¸ë‹¬ì„±",
                    "action_items": [
                        f"'{req['name']}' êµ¬í˜„ ì™„ë£Œ í•„ìš” (í˜„ì¬ {req['score']}/100)"
                        for req in low_score_reqs[:3]
                    ]
                })
        
        # ë¬¼ë¦¬ ë²•ì¹™ ê²€ì¦ ê²°ê³¼ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if 'physics_validation' in self.results:
            physics = self.results['physics_validation']
            missing_physics = [law for law, data in physics.items() if data['status'] != 'ì ìš©ë¨']
            
            if missing_physics:
                recommendations.append({
                    "category": "ë¬¼ë¦¬ ë²•ì¹™ ë¯¸ì ìš©",
                    "priority": "medium",
                    "description": f"{len(missing_physics)}ê°œ ë¬¼ë¦¬ ë²•ì¹™ ë¯¸ì ìš©",
                    "action_items": [
                        f"'{law.replace('_', ' ').title()}' ë¬¼ë¦¬ ë²•ì¹™ êµ¬í˜„ í•„ìš”"
                        for law in missing_physics[:3]
                    ]
                })
        
        # ì„¼ì„œ í†µí•© ê²°ê³¼ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if 'sensor_integration' in self.results:
            sensors = self.results['sensor_integration']
            missing_critical_sensors = [
                sensor for sensor_id, sensor in sensors.items()
                if sensor['priority'] == 'critical' and sensor['fields_count'] == 0
            ]
            
            if missing_critical_sensors:
                recommendations.append({
                    "category": "Critical ì„¼ì„œ ë¯¸í†µí•©",
                    "priority": "critical",
                    "description": f"{len(missing_critical_sensors)}ê°œ Critical ì„¼ì„œ ë¯¸í†µí•©",
                    "action_items": [
                        f"'{sensor['name']}' ì„¼ì„œ ë°ì´í„° í†µí•© í•„ìš”"
                        for sensor in missing_critical_sensors
                    ]
                })
        
        # íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if 'pipeline_performance' in self.results:
            performance = self.results['pipeline_performance']
            if performance['overall_score'] < 80:
                recommendations.append({
                    "category": "íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ ê°œì„ ",
                    "priority": "high",
                    "description": f"íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ ì ìˆ˜ {performance['overall_score']:.1f}/100",
                    "action_items": [
                        "ì‹¤ì‹œê°„ ì²˜ë¦¬ëŸ‰ ìµœì í™”",
                        "ë°ì´í„° ì§€ì—°ì‹œê°„ ë‹¨ì¶•",
                        "ë°ì´í„° í’ˆì§ˆ ê°œì„ "
                    ]
                })
        
        # í†µí•© ë²„ì „ ì œì‘ ê¶Œì¥ì‚¬í•­
        recommendations.append({
            "category": "í†µí•© ì‹œìŠ¤í…œ êµ¬ì¶•",
            "priority": "high",
            "description": "ë…ë¦½ëœ í†µí•© ë²„ì „ GLEC_DTG_INTEGRATED_v20.0 ì œì‘ í•„ìš”",
            "action_items": [
                "ëª¨ë“  êµ¬ì„±ìš”ì†Œ ë‹¨ì¼ íŒ¨í‚¤ì§€ í†µí•©",
                "ì¼ê´€ì„± ìˆëŠ” ì„¤ì¹˜/ë°°í¬ ìŠ¤í¬ë¦½íŠ¸ ì œì‘",
                "ì¢…í•© í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ êµ¬ì¶•",
                "ì‚¬ìš©ì ê°€ì´ë“œ ë° API ë¬¸ì„œ ì‘ì„±"
            ]
        })
        
        self.results['improvement_recommendations'] = recommendations
        
        print("ğŸ¯ ì¢…í•© ê°œì„  ê¶Œì¥ì‚¬í•­:")
        for i, rec in enumerate(recommendations, 1):
            priority_icon = "ğŸš¨" if rec['priority'] == 'critical' else "âš ï¸" if rec['priority'] == 'high' else "ğŸ“‹"
            print(f"\n{i}. {priority_icon} {rec['category']} ({rec['priority']} ìš°ì„ ìˆœìœ„)")
            print(f"   {rec['description']}")
            for action in rec['action_items']:
                print(f"   â€¢ {action}")
        
        return recommendations

    def save_audit_report(self):
        """ì „ìˆ˜ì¡°ì‚¬ ê²°ê³¼ ë³´ê³ ì„œ ì €ì¥"""
        report_filename = f"GLEC_DTG_COMPREHENSIVE_AUDIT_{self.audit_timestamp}.json"
        
        # JSONìœ¼ë¡œ ì €ì¥
        with open(report_filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2, default=str)
        
        # ë§ˆí¬ë‹¤ìš´ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
        md_filename = f"GLEC_DTG_AUDIT_SUMMARY_{self.audit_timestamp}.md"
        
        md_content = f"""# GLEC DTG ì‹œìŠ¤í…œ ì¢…í•© ì „ìˆ˜ì¡°ì‚¬ ë³´ê³ ì„œ

## ğŸ“Š ì¡°ì‚¬ ê°œìš”
- **ì¡°ì‚¬ ì‹œê°„**: {self.results['audit_info']['timestamp']}
- **ì¡°ì‚¬ ëª¨ë“œ**: {self.results['audit_info']['mode']}
- **ì¡°ì‚¬ ë²”ìœ„**: {self.results['audit_info']['scope']}

## ğŸ¯ í•µì‹¬ ê²°ê³¼ ìš”ì•½

### 15ê°€ì§€ ìš”êµ¬ì‚¬í•­ ë‹¬ì„±ë„
"""
        
        if 'requirements_analysis' in self.results:
            total_score = sum(req['score'] for req in self.results['requirements_analysis'].values()) / 15
            achieved = sum(1 for req in self.results['requirements_analysis'].values() if req['score'] >= 80)
            md_content += f"- **ì „ì²´ ë‹¬ì„±ë¥ **: {total_score:.1f}/100\n"
            md_content += f"- **ë‹¬ì„± ì™„ë£Œ**: {achieved}/15ê°œ ìš”êµ¬ì‚¬í•­\n\n"
        
        # ë¬¼ë¦¬ ë²•ì¹™ ì ìš©ë„
        if 'physics_validation' in self.results:
            applied = sum(1 for law in self.results['physics_validation'].values() if law['status'] == 'ì ìš©ë¨')
            total_laws = len(self.results['physics_validation'])
            md_content += f"### ë¬¼ë¦¬ ë²•ì¹™ ì ìš©ë„\n"
            md_content += f"- **ì ìš© ì™„ë£Œ**: {applied}/{total_laws}ê°œ ë¬¼ë¦¬ ë²•ì¹™\n\n"
        
        # ê°œì„  ê¶Œì¥ì‚¬í•­
        if 'improvement_recommendations' in self.results:
            md_content += f"### ì£¼ìš” ê°œì„  ê¶Œì¥ì‚¬í•­\n"
            for rec in self.results['improvement_recommendations'][:3]:
                md_content += f"- **{rec['category']}**: {rec['description']}\n"
        
        md_content += f"\n## ğŸ“ ìƒì„¸ ë°ì´í„°\nìƒì„¸ ë¶„ì„ ê²°ê³¼ëŠ” `{report_filename}` íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.\n"
        
        with open(md_filename, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        print(f"\nğŸ“ ì „ìˆ˜ì¡°ì‚¬ ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ:")
        print(f"   - ìƒì„¸ ë°ì´í„°: {report_filename}")
        print(f"   - ìš”ì•½ ë³´ê³ ì„œ: {md_filename}")
        
        return report_filename, md_filename

    def run_comprehensive_audit(self):
        """ì¢…í•© ì „ìˆ˜ì¡°ì‚¬ ì‹¤í–‰"""
        self.print_section("GLEC DTG ì‹œìŠ¤í…œ ì¢…í•© ì „ìˆ˜ì¡°ì‚¬ ì‹œì‘", level=1)
        
        print(f"ğŸ” ì œ3ì ê°ê´€í™” ëª¨ë“œë¡œ ì „ì²´ ì‹œìŠ¤í…œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        print(f"ğŸ“… ì¡°ì‚¬ ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            # Phase 1: ìš”êµ¬ì‚¬í•­ ë¶„ì„
            requirements = self.analyze_15_requirements()
            
            # Phase 2: ë¬¼ë¦¬ ë²•ì¹™ ê²€ì¦  
            physics = self.validate_physics_laws()
            
            # Phase 2-2: ì„¼ì„œ ë°ì´í„° í†µí•© í‰ê°€
            sensors = self.assess_sensor_data_integration()
            
            # Phase 3: ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ í‰ê°€
            pipeline = self.evaluate_data_pipeline_performance()
            
            # Phase 3-2: ê³ ì†ë„ë¡œ ì„±ëŠ¥ ë°ì´í„° ë¶„ì„
            highway_data = self.analyze_highway_performance_data()
            
            # Phase 4: ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±
            recommendations = self.generate_improvement_recommendations()
            
            # ë³´ê³ ì„œ ì €ì¥
            report_files = self.save_audit_report()
            
            self.print_section("ğŸ‰ ì¢…í•© ì „ìˆ˜ì¡°ì‚¬ ì™„ë£Œ", level=1)
            
            return {
                'success': True,
                'report_files': report_files,
                'summary': {
                    'requirements_achieved': sum(1 for req in requirements.values() if req['score'] >= 80),
                    'physics_applied': sum(1 for law in physics.values() if law['status'] == 'ì ìš©ë¨'),
                    'sensors_integrated': sum(1 for sensor in sensors.values() if sensor['fields_count'] > 0),
                    'pipeline_score': pipeline.get('overall_score', 0),
                    'recommendations_count': len(recommendations)
                }
            }
            
        except Exception as e:
            self.print_section(f"âŒ ì „ìˆ˜ì¡°ì‚¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", level=1)
            print(f"ì˜¤ë¥˜ ë‚´ìš©: {e}")
            return {'success': False, 'error': str(e)}

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    auditor = GLECSystemAuditor()
    result = auditor.run_comprehensive_audit()
    
    if result['success']:
        print(f"\nğŸŠ ì „ìˆ˜ì¡°ì‚¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ“Š ê²°ê³¼ ìš”ì•½:")
        summary = result['summary']
        print(f"   â€¢ ìš”êµ¬ì‚¬í•­ ë‹¬ì„±: {summary['requirements_achieved']}/15ê°œ")
        print(f"   â€¢ ë¬¼ë¦¬ ë²•ì¹™ ì ìš©: {summary['physics_applied']}/8ê°œ")  
        print(f"   â€¢ ì„¼ì„œ í†µí•©: {summary['sensors_integrated']}/8ê°œ")
        print(f"   â€¢ íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥: {summary['pipeline_score']:.1f}/100ì ")
        print(f"   â€¢ ê°œì„  ê¶Œì¥ì‚¬í•­: {summary['recommendations_count']}ê°œ")
    else:
        print(f"\nâŒ ì „ìˆ˜ì¡°ì‚¬ ì‹¤í–‰ ì‹¤íŒ¨: {result['error']}")

if __name__ == "__main__":
    main()